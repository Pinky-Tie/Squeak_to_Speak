{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_router import Route\n",
    "from semantic_router.encoders import OpenAIEncoder, HuggingFaceEncoder\n",
    "from semantic_router import RouteLayer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframes json files\n",
    "df_synthetic = pd.read_json(\"synthetic_intetions.json\")\n",
    "\n",
    "X_syn = df_synthetic[['Id','Message']]\n",
    "y_syn = df_synthetic['Intention'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['find_therapist',\n",
       " 'find_therapist',\n",
       " 'find_therapist',\n",
       " 'find_therapist',\n",
       " 'find_therapist',\n",
       " 'find_therapist',\n",
       " 'find_therapist',\n",
       " 'find_therapist',\n",
       " 'find_therapist',\n",
       " 'find_therapist',\n",
       " 'find_support_group',\n",
       " 'find_support_group',\n",
       " 'find_support_group',\n",
       " 'find_support_group',\n",
       " 'find_support_group',\n",
       " 'find_support_group',\n",
       " 'find_support_group',\n",
       " 'find_support_group',\n",
       " 'find_support_group',\n",
       " 'find_support_group',\n",
       " 'find_hotline',\n",
       " 'find_hotline',\n",
       " 'find_hotline',\n",
       " 'find_hotline',\n",
       " 'find_hotline',\n",
       " 'find_hotline',\n",
       " 'find_hotline',\n",
       " 'find_hotline',\n",
       " 'find_hotline',\n",
       " 'find_hotline',\n",
       " 'habit_alternatives',\n",
       " 'habit_alternatives',\n",
       " 'habit_alternatives',\n",
       " 'habit_alternatives',\n",
       " 'habit_alternatives',\n",
       " 'habit_alternatives',\n",
       " 'habit_alternatives',\n",
       " 'habit_alternatives',\n",
       " 'habit_alternatives',\n",
       " 'habit_alternatives',\n",
       " 'insert_mood',\n",
       " 'insert_mood',\n",
       " 'insert_mood',\n",
       " 'insert_mood',\n",
       " 'insert_mood',\n",
       " 'insert_mood',\n",
       " 'insert_mood',\n",
       " 'insert_mood',\n",
       " 'insert_mood',\n",
       " 'insert_mood',\n",
       " 'insert_journal',\n",
       " 'insert_journal',\n",
       " 'insert_journal',\n",
       " 'insert_journal',\n",
       " 'insert_journal',\n",
       " 'insert_journal',\n",
       " 'insert_journal',\n",
       " 'insert_journal',\n",
       " 'insert_journal',\n",
       " 'insert_journal',\n",
       " 'ask_missionvalues',\n",
       " 'ask_missionvalues',\n",
       " 'ask_missionvalues',\n",
       " 'ask_missionvalues',\n",
       " 'ask_missionvalues',\n",
       " 'ask_missionvalues',\n",
       " 'ask_missionvalues',\n",
       " 'ask_missionvalues',\n",
       " 'ask_missionvalues',\n",
       " 'ask_missionvalues',\n",
       " 'ask_features',\n",
       " 'ask_features',\n",
       " 'ask_features',\n",
       " 'ask_features',\n",
       " 'ask_features',\n",
       " 'ask_features',\n",
       " 'ask_features',\n",
       " 'ask_features',\n",
       " 'ask_features',\n",
       " 'ask_features',\n",
       " 'review_user_memory',\n",
       " 'review_user_memory',\n",
       " 'review_user_memory',\n",
       " 'review_user_memory',\n",
       " 'review_user_memory',\n",
       " 'review_user_memory',\n",
       " 'review_user_memory',\n",
       " 'review_user_memory',\n",
       " 'review_user_memory',\n",
       " 'review_user_memory',\n",
       " 'update_journal',\n",
       " 'update_journal',\n",
       " 'update_journal',\n",
       " 'update_journal',\n",
       " 'update_journal',\n",
       " 'update_journal',\n",
       " 'update_journal',\n",
       " 'update_journal',\n",
       " 'update_journal',\n",
       " 'update_journal',\n",
       " 'chat_about_journal',\n",
       " 'chat_about_journal',\n",
       " 'chat_about_journal',\n",
       " 'chat_about_journal',\n",
       " 'chat_about_journal',\n",
       " 'chat_about_journal',\n",
       " 'chat_about_journal',\n",
       " 'chat_about_journal',\n",
       " 'chat_about_journal',\n",
       " 'chat_about_journal',\n",
       " 'insert_gratitude',\n",
       " 'insert_gratitude',\n",
       " 'insert_gratitude',\n",
       " 'insert_gratitude',\n",
       " 'insert_gratitude',\n",
       " 'insert_gratitude',\n",
       " 'insert_gratitude',\n",
       " 'insert_gratitude',\n",
       " 'insert_gratitude',\n",
       " 'insert_gratitude',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_syn, y_syn, test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"None\" with None\n",
    "y_train = [None if i == \"None\" else i for i in y_train]\n",
    "y_test = [None if i == \"None\" else i for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for each intention\n",
    "find_therapist_messages = []\n",
    "find_support_group_messages = []\n",
    "find_hotline_messages = []\n",
    "habit_alternatives_messages = []\n",
    "insert_mood_messages = []\n",
    "insert_journal_messages = []\n",
    "ask_missionvalues_messages = []\n",
    "ask_features_messages = []\n",
    "review_user_memory_messages = []\n",
    "update_journal_messages = []\n",
    "chat_about_journal_messages = []\n",
    "gratitude_messages = []\n",
    "\n",
    "# Categorize messages based on labels\n",
    "for message, label in zip(X_train[\"Message\"], y_train):\n",
    "    if label == \"find_therapist\":\n",
    "        find_therapist_messages.append(message)\n",
    "    elif label == \"find_support_group\":\n",
    "        find_support_group_messages.append(message)\n",
    "    elif label == \"find_hotline\":\n",
    "        find_hotline_messages.append(message)\n",
    "    elif label == \"habit_alternatives\":\n",
    "        habit_alternatives_messages.append(message)\n",
    "    elif label == \"insert_mood\":\n",
    "        insert_mood_messages.append(message)\n",
    "    elif label == \"insert_journal\":\n",
    "        insert_journal_messages.append(message)\n",
    "    elif label == \"ask_missionvalues\":\n",
    "        ask_missionvalues_messages.append(message)\n",
    "    elif label == \"ask_features\":\n",
    "        ask_features_messages.append(message)\n",
    "    elif label == \"review_user_memory\":\n",
    "        review_user_memory_messages.append(message)\n",
    "    elif label == \"update_journal\":\n",
    "        update_journal_messages.append(message)\n",
    "    elif label == \"chat_about_journal\":\n",
    "        chat_about_journal_messages.append(message)\n",
    "    elif label == \"entry_gratitude\":\n",
    "        gratitude_messages.append(message)    \n",
    "\n",
    "# Define routes for each intention\n",
    "find_therapist = Route(\n",
    "    name=\"find_therapist\",\n",
    "    description=\"The user wants to receive a personalized recommendation for a healthcare professional.\",\n",
    "    utterances=find_therapist_messages,\n",
    ")\n",
    "\n",
    "find_support_group = Route(\n",
    "    name=\"find_support_group\",\n",
    "    description=\"The user wants to find support groups in their vicinity.\",\n",
    "    utterances=find_support_group_messages,\n",
    ")\n",
    "\n",
    "find_hotline = Route(\n",
    "    name=\"find_hotline\",\n",
    "    description=\"The user wants to access the contact information for emergency or non-emergency hotlines.\",\n",
    "    utterances=find_hotline_messages,\n",
    ")\n",
    "\n",
    "habit_alternatives = Route(\n",
    "    name=\"habit_alternatives\",\n",
    "    description=\"The user wants to find a healthier or more sustainable alternative to a habit they currently have.\",\n",
    "    utterances=habit_alternatives_messages,\n",
    ")\n",
    "\n",
    "insert_mood = Route(\n",
    "    name=\"insert_mood\",\n",
    "    description=\"The user wants to record their thoughts, feelings, or reflections by making an entry in their journal or mood board.\",\n",
    "    utterances=insert_mood_messages,\n",
    ")\n",
    "\n",
    "insert_journal = Route(\n",
    "    name=\"insert_journal\",\n",
    "    description=\"The user wants to contribute a message of gratitude or positivity to the community gratitude banner.\",\n",
    "    utterances=insert_journal_messages,\n",
    ")\n",
    "\n",
    "ask_missionvalues = Route(\n",
    "    name=\"ask_missionvalues\",\n",
    "    description=\"The user wants to learn about the mission, vision, and values of Squeak to Speak.\",\n",
    "    utterances=ask_missionvalues_messages,\n",
    ")\n",
    "\n",
    "ask_features = Route(\n",
    "    name=\"ask_features\",\n",
    "    description=\"The user wants an overview of the features and functionalities of Squeak to Speak.\",\n",
    "    utterances=ask_features_messages,\n",
    ")\n",
    "\n",
    "review_user_memory = Route(\n",
    "    name=\"review_user_memory\",\n",
    "    description=\"The user wants to review the data that Squeak to Speak has collected about them.\",\n",
    "    utterances=review_user_memory_messages,\n",
    ")\n",
    "\n",
    "update_journal = Route(\n",
    "    name=\"update_journal\",\n",
    "    description=\"The user wants to modify an existing entry in their journal or mood board.\",\n",
    "    utterances=update_journal_messages,\n",
    ")\n",
    "\n",
    "chat_about_journal = Route(\n",
    "    name=\"chat_about_journal\",\n",
    "    description=\"The user wants to engage in a conversation with the chatbot, leveraging the knowledge of their past journal entries.\",\n",
    "    utterances=chat_about_journal_messages,\n",
    ")\n",
    "\n",
    "insert_gratitude = Route(\n",
    "    name=\"insert_gratitude\",\n",
    "    description=\"The user wants to insert their gratitude message into the database\",\n",
    "    utterances=gratitude_messages,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = [\n",
    "        review_user_memory,\n",
    "        find_therapist,\n",
    "        find_support_group,\n",
    "        find_hotline,\n",
    "        habit_alternatives,\n",
    "        insert_mood,\n",
    "        insert_journal,\n",
    "        ask_missionvalues,\n",
    "        ask_features,\n",
    "        review_user_memory,\n",
    "        update_journal,\n",
    "        chat_about_journal,\n",
    "        insert_gratitude\n",
    "        ]\n",
    "encoder = HuggingFaceEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_rl = RouteLayer(encoder=encoder, routes=routes) #aggregation = \"mean\", \"max\" or \"sum\". #top_k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n",
      "Training: 100%|██████████| 500/500 [01:20<00:00,  6.19it/s, acc=0.84]\n"
     ]
    }
   ],
   "source": [
    "# Call the fit method\n",
    "hf_rl.fit(X=X_train[\"Message\"].to_list(), y=y_train, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s]\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.83it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  9.23it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.96it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.38it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  9.94it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.95it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intention                Test Inputs    Correct   Incorrect Accuracy (%)   \n",
      "find_therapist           3              3         0         100.0          \n",
      "insert_journal           3              2         1         66.67          \n",
      "insert_mood              3              1         2         33.33          \n",
      "find_hotline             2              2         0         100.0          \n",
      "ask_missionvalues        2              2         0         100.0          \n",
      "update_journal           6              0         6         0.0            \n",
      "insert_gratitude         1              0         1         0.0            \n",
      "find_support_group       2              2         0         100.0          \n",
      "ask_features             1              1         0         100.0          \n",
      "review_user_memory       2              0         2         0.0            \n",
      "Average Accuracy         25             13        12        52.0           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Initialize counters for each intention\n",
    "results = defaultdict(lambda: {\"Test Inputs\": 0, \"Correct\": 0, \"Incorrect\": 0})\n",
    "\n",
    "# Iterate through test data to manually evaluate predictions\n",
    "for message, true_label in zip(X_test[\"Message\"], y_test):\n",
    "    # Evaluate the single message to get the prediction\n",
    "    single_accuracy = hf_rl.evaluate(X=[message], y=[true_label])\n",
    "    \n",
    "    # Increment the total test inputs for the true label\n",
    "    results[true_label][\"Test Inputs\"] += 1\n",
    "    \n",
    "    # Increment correct or incorrect based on single message evaluation accuracy\n",
    "    if single_accuracy == 1.0:  # Perfect match means prediction was correct\n",
    "        results[true_label][\"Correct\"] += 1\n",
    "    else:\n",
    "        results[true_label][\"Incorrect\"] += 1\n",
    "\n",
    "# Calculate accuracy for each intention\n",
    "for intention, data in results.items():\n",
    "    data[\"Accuracy (%)\"] = round((data[\"Correct\"] / data[\"Test Inputs\"]) * 100, 2)\n",
    "\n",
    "# Display the results in table format\n",
    "print(f\"{'Intention':<25}{'Test Inputs':<15}{'Correct':<10}{'Incorrect':<10}{'Accuracy (%)':<15}\")\n",
    "for intention, data in results.items():\n",
    "    print(f\"{intention:<25}{data['Test Inputs']:<15}{data['Correct']:<10}{data['Incorrect']:<10}{data['Accuracy (%)']:<15}\")\n",
    "\n",
    "# Calculate overall accuracy\n",
    "total_inputs = sum(data[\"Test Inputs\"] for data in results.values())\n",
    "total_correct = sum(data[\"Correct\"] for data in results.values())\n",
    "overall_accuracy = round((total_correct / total_inputs) * 100, 2)\n",
    "\n",
    "print(f\"{'Average Accuracy':<25}{total_inputs:<15}{total_correct:<10}{total_inputs - total_correct:<10}{overall_accuracy:<15}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-01-03 16:15:16 INFO semantic_router.utils.logger Saving route config to layer.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "hf_rl.to_json(\"layer.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
